# AI Responsible Use Policy â€“ Lexie

**System:** Lexie â€“ Compliance Copilot  
**Version:** 1.0  
**Date:** September 4, 2025  
**Next review:** September 2026  
**AI System Owner:** Virginia Levy Abulafia  

---

## ğŸ¯ Purpose
Lexie is an Agentic AI system designed to support the analysis of policy documents and free text related to AI governance. It compares input against key articles of the GDPR and the EU AI Act, returning human-readable PDF reports with risk scores, violations, citations, and recommendations.

---

## ğŸŒ± Guiding Principles
- **Transparency** â€“ Compliance logic is encoded in structured policy files (YAML/Markdown). Outputs are validated against a strict JSON schema, but no machine-readable logs are stored.  
- **Mandatory Human Oversight** â€“ Lexie does not replace compliance officers. Reports must be reviewed and validated by authorized staff.  
- **Data Minimization** â€“ Lexie processes inputs transiently and returns only PDF reports.  
- **Content Neutrality** â€“ Outputs are limited to compliance analysis and not suitable for critical domains such as medical or legal advice.  
- **Proportionate Responsibility** â€“ Technical operation is guaranteed within declared limits; misuse is excluded.  
- **Continuous Improvement** â€“ Lexie is periodically reviewed and updated transparently.  

---

## ğŸ“Œ Organizational Commitments
- Operate in alignment with ISO/IEC 42001:2023, EU AI Act, and GDPR.  
- Maintain documented risk and impact assessments.  
- Release only tested and traceable versions.  
- Inform users about system limits and disclaimers.  
- Collect and integrate user feedback.  

---

## âœï¸ Approval
Approved on September 4, 2025. To be reviewed within 12 months.  

**AI System Owner:** Virginia Levy Abulafia  
**Signature:** Digital or equivalent approval
